{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae9aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os    \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9f11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "\n",
    "df_hu_head = pandas.read_csv(pwd+'/feature_data/hu_head.csv')\n",
    "df_hu_head = df_hu_head.drop(df_hu_head.columns[0], axis=1)\n",
    "\n",
    "df_hu_tail = pandas.read_csv(pwd+'/feature_data/hu_tail.csv')\n",
    "df_hu_tail = df_hu_tail.drop(df_hu_tail.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c02a0d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics targeted at Classification Models\n",
    "\n",
    "<b>Precision</b>: It measures the proportion of correctly predicted positive instances out of the total predicted positive instances. It indicates how reliable the model is when predicting positive outcomes.\n",
    "\n",
    "<b>Recall</b> (Sensitivity or True Positive Rate): It measures the proportion of correctly predicted positive instances out of the actual positive instances. It indicates how well the model identifies positive instances.\n",
    "\n",
    "<b>F1 Score</b>: It is the harmonic mean of precision and recall. It provides a balanced measure of both precision and recall.\n",
    "\n",
    "<b>Specificity</b> (True Negative Rate): It measures the proportion of correctly predicted negative instances out of the actual negative instances. It indicates how well the model identifies negative instances.\n",
    "\n",
    "<b>Confusion Matrix</b>: It provides a tabular representation of the model's predictions against the actual class labels, showing the counts of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "<b>Classification Report</b>: It provides a summary of various evaluation metrics including precision, recall, F1 score, and support for each class label.\n",
    "\n",
    "# Regression Models \n",
    "\n",
    "<b>Linear Regression</b> (Ordinary Least Squares): This is a basic linear regression model that assumes a linear relationship between the input features and the target variable. It minimizes the sum of squared residuals to fit a linear function to the data.\n",
    "\n",
    "<b>Ridge Regression</b>: Ridge regression is a regularized version of linear regression that adds a penalty term to the loss function. It helps to reduce the impact of multicollinearity in the data and can prevent overfitting.\n",
    "\n",
    "<b>Lasso Regression</b>: Lasso regression is another regularized linear regression model that uses L1 regularization. It can be useful for feature selection as it tends to set the coefficients of less important features to zero.\n",
    "\n",
    "<b>ElasticNet Regression</b>: ElasticNet regression combines both L1 (Lasso) and L2 (Ridge) regularization. It can be effective when dealing with datasets that have a large number of features and potential collinearity.\n",
    "\n",
    "\n",
    "# Evaluation Metrics targeted at Regression Models\n",
    "\n",
    "<b>Mean Squared Error (MSE)</b>: It measures the average squared difference between the predicted and actual values. Lower values indicate better performance.\n",
    "\n",
    "<b>Mean Absolute Error (MAE)</b>: It measures the average absolute difference between the predicted and actual values. It is less sensitive to outliers compared to MSE.\n",
    "\n",
    "<b>R-squared (R2) Score</b>: It represents the proportion of the variance in the target variable that is predictable from the features. It ranges from 0 to 1, with 1 indicating a perfect fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc1eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_generator \n",
    "    \n",
    "hu_head = model_generator.coin_models(df_hu_head,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2b54d",
   "metadata": {},
   "source": [
    "# Head Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17128b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hh_knn = hu_head.classification_correctness(hu_head.KNN(5),\"K Nearest Neighbour\")\n",
    "hh_DecisionTree = hu_head.classification_correctness(hu_head.DecisionTree(),\"Decision Tree\")\n",
    "hh_svc = hu_head.classification_correctness(hu_head.SVC(),\"SVC\") \n",
    "hh_rf = hu_head.classification_correctness(hu_head.RandomForest(100),\"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bcfa660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics for: Logistic Regression\n",
      "Mean Squared Error (MSE): 6.458\n",
      "Mean Absolute Error (MAE): 1.708\n",
      "R-squared (R2) Score: -0.824\n",
      "\n",
      "Evaluation metrics for: Linear Regression\n",
      "Mean Squared Error (MSE): 3.263\n",
      "Mean Absolute Error (MAE): 1.481\n",
      "R-squared (R2) Score: 0.078\n",
      "\n",
      "Evaluation metrics for: ridge Regression\n",
      "Mean Squared Error (MSE): 3.586\n",
      "Mean Absolute Error (MAE): 1.666\n",
      "R-squared (R2) Score: -0.013\n",
      "\n",
      "Evaluation metrics for: lasso Regression\n",
      "Mean Squared Error (MSE): 3.586\n",
      "Mean Absolute Error (MAE): 1.666\n",
      "R-squared (R2) Score: -0.013\n",
      "\n",
      "Evaluation metrics for: Elastic Net Regression Regression\n",
      "Mean Squared Error (MSE): 3.586\n",
      "Mean Absolute Error (MAE): 1.666\n",
      "R-squared (R2) Score: -0.013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hh_reg_log = hu_head.regrssion_correctness(hu_head.logistic_regression(),\"Logistic Regression\")\n",
    "hh_reg_lin = hu_head.regrssion_correctness(hu_head.linear_regression(),\"Linear Regression\")\n",
    "hh_reg_ridge = hu_head.regrssion_correctness(hu_head.ridge_regression(0.5),\"ridge Regression\")\n",
    "hh_reg_lasso = hu_head.regrssion_correctness(hu_head.lasso_regression(0.5),\"lasso Regression\")\n",
    "hh_reg_enr = hu_head.regrssion_correctness(hu_head.elastic_net_regression(alpha =0.1,l1_ratio =0.5),\"Elastic Net Regression Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d2c99",
   "metadata": {},
   "source": [
    "# Tail analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0d566b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hu_tail = model_generator.coin_models(df_hu_tail,0.8)\n",
    "\n",
    "hh_knn = hu_tail.classification_correctness(hu_head.KNN(5),\"K Nearest Neighbour\")\n",
    "hh_DecisionTree = hu_tail.classification_correctness(hu_head.DecisionTree(),\"Decision Tree\")\n",
    "hh_svc = hu_tail.classification_correctness(hu_head.SVC(),\"SVC\") \n",
    "hh_rf = hu_tail.classification_correctness(hu_head.RandomForest(100),\"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d92182",
   "metadata": {},
   "source": [
    "# How to apply models in real-life\n",
    "\n",
    "Utilizing two distinct models, one for classifying the \"head\" and another for classifying the \"tail,\" the image is subjected to both models, and the outcome with the highest score is considered.\n",
    "\n",
    "Given the inherent nature of coins, where they can exclusively exhibit either the \"heads\" or \"tails\" side, and the challenge in simultaneously observing both sides, the adoption of individual models for each side presents notable advantages.\n",
    "\n",
    "This rationale can be extended to encompass various deep learning models such as convolutional neural networks, LSTM, GRU, among others.\n",
    "\n",
    "The software architecture employed in this project facilitates seamless integration of additional functionalities, offering ease of implementation for future extensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
